{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee, geemap, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intialize Geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = geemap.Map(center=(10.41, 37.62), zoom=11)\n",
    "\n",
    "jedeb = ee.FeatureCollection(\"projects/ee-yilkalg3/assets/Jedeb_Watershed\")\n",
    "#Map.addLayer(jedeb, {}, 'Jedeb Watershed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2021-12-01'\n",
    "end = '2022-04-30'\n",
    "season = ee.Filter.date(start,end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Median Sentinel 2 Reflectance \n",
    "def maskS2clouds(image):\n",
    "  qa = image.select('QA60')\n",
    "\n",
    "  # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "  cloudBitMask = 1 << 10\n",
    "  cirrusBitMask = 1 << 11\n",
    "\n",
    "  # Both flags should be set to zero, indicating clear conditions.\n",
    "  mask = qa.bitwiseAnd(cloudBitMask).eq(0) \\\n",
    "      .And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "\n",
    "  return image.updateMask(mask).divide(10000)\n",
    "\n",
    "# Filter the first Sentinel 2 image of the month\n",
    "sentinel2 = ee.ImageCollection('COPERNICUS/S2_SR')\\\n",
    "    .filterBounds(jedeb)\\\n",
    "    .filter(season)\\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',20))\\\n",
    "    .map(maskS2clouds)\n",
    " \n",
    "# Median image\n",
    "s2median = ee.Image(sentinel2.median()).clip(jedeb)\n",
    "s2median.bandNames().getInfo()\n",
    "\n",
    "visualization = {\n",
    "  'min': 0.0,\n",
    "  'max': 0.3,\n",
    "  'bands': ['B4', 'B3', 'B2'],\n",
    "}\n",
    "\n",
    "Map.addLayer(s2median, visualization, 'RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896\n"
     ]
    }
   ],
   "source": [
    "points = ee.FeatureCollection(\"projects/ee-yilkalg3/assets/TrainingJ\")\n",
    "print(points.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these bands for prediction (excluding red edge bands).\n",
    "bands = ['B2', 'B3', 'B4', 'B5', 'B6','B7','B8', 'B8A', 'B11', 'B12']\n",
    "\n",
    "# This property of the table stores the land cover labels.\n",
    "label = 'Cover'\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "sample = s2median.select(bands).sampleRegions(\n",
    "    **{'collection': points, 'properties': [label], 'scale': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ee.Classifier.libsvm(**{\n",
    "  'kernelType': 'RBF',\n",
    "  'gamma': 0.5,\n",
    "  'cost': 128\n",
    "}).train(sample, label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the image with the same bands used for training \n",
    "classified_RF1 = s2median.select(bands).classify(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = classifier.confusionMatrix()\n",
    "#train_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.accuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.producersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.consumersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "validationGcp = ee.FeatureCollection(\"projects/ee-yilkalg3/assets/ValidationJ\")\n",
    "print(validationGcp.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validationGcp.first().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This property of the table stores the land cover labels.\n",
    "label = 'Cover'\n",
    "\n",
    "band = ['classification']\n",
    "# Overlay the points on the imagery to get training.\n",
    "test = classified_RF1.select(band).sampleRegions(\n",
    "    **{'collection': validationGcp, 'properties':[label],'scale': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 3, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 56, 0, 7, 6, 0, 0],\n",
       " [0, 0, 2, 20, 1, 11, 0, 0],\n",
       " [0, 0, 6, 0, 37, 0, 0, 1],\n",
       " [0, 0, 1, 1, 0, 49, 0, 2],\n",
       " [0, 0, 0, 0, 0, 0, 12, 0],\n",
       " [0, 0, 0, 0, 0, 2, 0, 7]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy = test.errorMatrix('Cover', 'classification')\n",
    "test_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8177777777777778"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.accuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666388404037339"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [1],\n",
       " [0.8],\n",
       " [0.5882352941176471],\n",
       " [0.8409090909090909],\n",
       " [0.9245283018867925],\n",
       " [1],\n",
       " [0.7777777777777778]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.producersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  0.75,\n",
       "  0.8615384615384616,\n",
       "  0.9523809523809523,\n",
       "  0.8222222222222222,\n",
       "  0.7205882352941176,\n",
       "  1,\n",
       "  0.7]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.consumersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentinel 1 GRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Sentinel-1 collection\n",
    "sentinel1 =  ee.ImageCollection('COPERNICUS/S1_GRD')\\\n",
    "                .filterBounds(jedeb)\\\n",
    "                .filter(season)\\\n",
    "                .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "                .filter(ee.Filter.eq('resolution_meters', 10)) \n",
    "                \n",
    "# Number of tiles in the season\n",
    "sentinel1 = sentinel1.sort('system:time_start')\n",
    "sentinel1.size().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12/02/21',\n",
       " '12/14/21',\n",
       " '12/26/21',\n",
       " '01/07/22',\n",
       " '01/19/22',\n",
       " '01/31/22',\n",
       " '02/12/22',\n",
       " '02/24/22',\n",
       " '03/08/22',\n",
       " '03/20/22',\n",
       " '04/01/22',\n",
       " '04/13/22',\n",
       " '04/25/22']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the acquisition times in the collection, formatted with Python's time module\n",
    "acq_times = sentinel1.aggregate_array('system:time_start').getInfo()\n",
    "[time.strftime('%x', time.gmtime(acq_time/1000)) for acq_time in acq_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using monthly mean backscatter \n",
    "\n",
    "s1Dec = ee.Image(sentinel1.filterDate(\"2021-12-01\",\"2021-12-31\").mean()).select([\"VV\",\"VH\"],[\"VVdec\",\"VHdec\"])\n",
    "s1Jan = ee.Image(sentinel1.filterDate(\"2022-01-01\",\"2022-01-31\").mean()).select([\"VV\",\"VH\"],[\"VVjan\",\"VHjan\"]);\n",
    "s1Feb = ee.Image(sentinel1.filterDate(\"2022-02-01\",\"2022-02-28\").mean()).select([\"VV\",\"VH\"],[\"VVfeb\",\"VHfeb\"])\n",
    "s1Mar = ee.Image(sentinel1.filterDate(\"2022-03-01\",\"2022-03-31\").mean()).select([\"VV\",\"VH\"],[\"VVmar\",\"VHmar\"])\n",
    "s1Apr = ee.Image(sentinel1.filterDate(\"2022-04-01\",\"2022-04-30\").mean()).select([\"VV\",\"VH\"],[\"VVapr\",\"VHapr\"])\n",
    "\n",
    "sentinel1mean = s1Dec.addBands(s1Jan)\\\n",
    "                 .addBands(s1Feb)\\\n",
    "                 .addBands(s1Mar)\\\n",
    "                 .addBands(s1Apr)\n",
    "\n",
    "#print(sentinel1mean.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speckle filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack Sentinel 1 and Sentinel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite = ee.Image.cat([(s2median),(sentinel1mean)])\n",
    "sentinel = composite.clip(jedeb)\n",
    "#print(Sentinel.getInfo())\n",
    "\n",
    "#Apply reduce the radar speckle by smoothing  \n",
    "smoothing_radius = 10\n",
    "#sentinel = sentinel.focal_mean(smoothing_radius, 'circle', 'meters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['VVdec', 'VHdec', 'VVjan', 'VHjan', 'VVfeb', 'VHfeb', 'VVmar', 'VHmar', 'VVapr', 'VHapr']\n",
    "# This property of the table stores the land cover labels.\n",
    "label = 'Cover'\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "sample = sentinel.select(bands).sampleRegions(\n",
    "    **{'collection': points, 'properties': [label], 'scale': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ee.Classifier.libsvm(**{\n",
    "  'kernelType': 'RBF',\n",
    "  'gamma': 0.9,\n",
    "  'cost': 128\n",
    "}).train(sample, label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the image with the same bands used for training.\n",
    "classified_RF2 = sentinel.select(bands).classify(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = classifier.confusionMatrix()\n",
    "#train_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.accuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.producersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.consumersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This property of the table stores the land cover labels.\n",
    "label = 'Cover'\n",
    "\n",
    "band = ['classification']\n",
    "# Overlay the points on the imagery to get training.\n",
    "test = classified_RF2.select(band).sampleRegions(\n",
    "    **{'collection': validationGcp, 'properties':[label],'scale': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test.errorMatrix('Cover', 'classification')\n",
    "#test_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3288888888888889"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.accuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029950890817725024"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [1],\n",
       " [0.029411764705882353],\n",
       " [0.045454545454545456],\n",
       " [0],\n",
       " [0],\n",
       " [0.1111111111111111]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.producersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0.3167420814479638, 1, 1, 0, 0, 1]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.consumersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Classification using Vegetation Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vegetation Indices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Image', 'bands': [{'id': 'EVI', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n"
     ]
    }
   ],
   "source": [
    "def getEVI(image):\n",
    "    # Compute the EVI using an expression.\n",
    "    EVI = image.expression(\n",
    "        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "            'NIR': image.select('B8'),\n",
    "            'RED': image.select('B4'),\n",
    "            'BLUE': image.select('B2')\n",
    "        }).rename(\"EVI\")\n",
    "\n",
    "    image = image.addBands(EVI)\n",
    "\n",
    "    return(image)\n",
    "\n",
    "evi = sentinel2.map(getEVI).median().clip(jedeb).select('EVI')\n",
    "\n",
    "print(evi.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Image', 'bands': [{'id': 'NDVI', 'data_type': {'type': 'PixelType', 'precision': 'float'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n"
     ]
    }
   ],
   "source": [
    "# Calculate NDVI\n",
    "def getNDVI(image):\n",
    "    # Compute the EVI using an expression.\n",
    "    NDVI = image.expression(\n",
    "        '((NIR - RED) / (NIR + RED ))', {\n",
    "            'NIR': image.select('B8'),\n",
    "            'RED': image.select('B4'),\n",
    "        }).rename(\"NDVI\")\n",
    "\n",
    "    image = image.addBands(NDVI)\n",
    "\n",
    "    return(image)\n",
    "\n",
    "ndvi = sentinel2.map(getNDVI).median().clip(jedeb).select('NDVI')\n",
    "\n",
    "print(ndvi.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Image', 'bands': [{'id': 'NDBI', 'data_type': {'type': 'PixelType', 'precision': 'float'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n"
     ]
    }
   ],
   "source": [
    "# Calculate NDBI\n",
    "def getNDBI(image):\n",
    "    # Compute the EVI using an expression.\n",
    "    NDBI = image.expression(\n",
    "        '((SWIR - NIR) / (SWIR + NIR ))', {\n",
    "            'SWIR': image.select('B11'),\n",
    "            'NIR': image.select('B8'),\n",
    "        }).rename(\"NDBI\")\n",
    "\n",
    "    image = image.addBands(NDBI)\n",
    "\n",
    "    return(image)\n",
    "\n",
    "ndbi = sentinel2.map(getNDBI).median().clip(jedeb).select('NDBI')\n",
    "\n",
    "print(ndbi.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite = ee.Image.cat([(sentinel),(evi),(ndvi),(ndbi)])\n",
    "\n",
    "sentinel_vi = composite.clip(jedeb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['B2', 'B3', 'B4','B8', 'B8A', 'B11', 'B12',\\\n",
    "        'VVdec', 'VHdec', 'VVjan', 'VHjan', 'VVfeb', 'VHfeb', 'VVmar', 'VHmar', 'VVapr', 'VHapr','EVI','NDBI']\n",
    "# This property of the table stores the land cover labels.\n",
    "label = 'Cover'\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "sample = sentinel_vi.select(bands).sampleRegions(\n",
    "    **{'collection': points, 'properties': [label], 'scale': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ee.Classifier.libsvm(**{\n",
    "  'kernelType': 'RBF',\n",
    "  'gamma': 0.5,\n",
    "  'cost': 128\n",
    "}).train(sample, label, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the image with the same bands used for training.\n",
    "classified_RF3 = sentinel_vi.select(bands).classify(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = classifier.confusionMatrix()\n",
    "#train_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.accuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.producersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_accuracy.consumersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This property of the table stores the land cover labels.\n",
    "label = 'Cover'\n",
    "\n",
    "band = ['classification']\n",
    "# Overlay the points on the imagery to get training.\n",
    "test = classified_RF3.select(band).sampleRegions(\n",
    "    **{'collection': validationGcp, 'properties':[label],'scale': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = test.errorMatrix('Cover', 'classification')\n",
    "#test_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3288888888888889"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.accuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029950890817725024"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [1],\n",
       " [0.029411764705882353],\n",
       " [0.045454545454545456],\n",
       " [0],\n",
       " [0],\n",
       " [0.1111111111111111]]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.producersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 0.3167420814479638, 1, 1, 0, 0, 1]]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy.consumersAccuracy().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191dd85476894aa9898cb166dc7dbb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[10.41, 37.62], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(childre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a palette for the classification.\n",
    "Palette = [\n",
    "    '419BDF', #water\n",
    "    '397D49', #trees\n",
    "    '88B053', #grass\n",
    "    '6efc6a', #irrigation\n",
    "    'E49635', #crops\n",
    "    'C4281B', #built\n",
    "    'A59B8F', #bare\n",
    "]\n",
    "Map.addLayer(classified_RF1, {'palette': Palette, 'min': 1, 'max': 7}, 'classification')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 3462370000.1460667}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total area of a single class (eq(*))     * is the class number \n",
    "total_area = classified_RF1.multiply(ee.Image.pixelArea()).reduceRegion(**{\n",
    "  'reducer': ee.Reducer.sum(),\n",
    "  'geometry': jedeb.geometry(),\n",
    "  'scale': 10,\n",
    "  'maxPixels': 1e9\n",
    "})\n",
    "\n",
    "total_area.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 67787189.58949104}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total area of a single class (eq(*))     * is the class number \n",
    "area = classified_RF1.eq(4).multiply(ee.Image.pixelArea()).reduceRegion(**{\n",
    "  'reducer': ee.Reducer.sum(),\n",
    "  'geometry': jedeb.geometry(),\n",
    "  'scale': 10,\n",
    "  'maxPixels': 1e9\n",
    "})\n",
    "\n",
    "area.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 285450.90710392373}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total area of a single class (eq(*))     * is the class number \n",
    "area = classified_RF2.eq(4).multiply(ee.Image.pixelArea()).reduceRegion(**{\n",
    "  'reducer': ee.Reducer.sum(),\n",
    "  'geometry': jedeb.geometry(),\n",
    "  'scale': 10,\n",
    "  'maxPixels': 1e9\n",
    "})\n",
    "\n",
    "area.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification': 278903.3173364677}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total area of a single class (eq(*))     * is the class number \n",
    "area = classified_RF3.eq(4).multiply(ee.Image.pixelArea()).reduceRegion(**{\n",
    "  'reducer': ee.Reducer.sum(),\n",
    "  'geometry': jedeb.geometry(),\n",
    "  'scale': 10,\n",
    "  'maxPixels': 1e9\n",
    "})\n",
    "\n",
    "area.getInfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "4b3fb90bd6b7d8679889b46ac4d1d0121d2987c392f20258ab967f9a09892f99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
